{
  
    
        "post0": {
            "title": "[kaggle] Spaceship Titanic í•„ì‚¬",
            "content": "Spaceship Titanic . &#128675;&#8205;&#9794;&#65039;&#47785;&#51201; . ìš°ì£¼ì„  íƒ€ì´íƒ€ë‹‰ ì–´ë–¤ ìŠ¹ê°ì´ ë‹¤ë¥¸ ì°¨ì›ìœ¼ë¡œ ì´ë™í• ì§€ ì˜ˆì¸¡ . &lt;/br&gt; . &#129513;&#53945;&#51669; . ìš°ì£¼ ë¯¸ìŠ¤í„°ë¦¬ë¥¼ í’€ê¸° ìœ„í•´ ì—¬ëŸ¬ë¶„ì˜ ë°ì´í„° ê³¼í•™ ê¸°ìˆ ì´ í•„ìš”í•œ 2912ë…„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. 4ê´‘ë…„ ë–¨ì–´ì§„ ê³³ì—ì„œ ì „ì†¡ì´ ì™”ëŠ”ë° ìƒí™©ì´ ì¢‹ì§€ ì•Šì•„ìš” . ìš°ì£¼ì„  íƒ€ì´íƒ€ë‹‰ì€ í•œ ë‹¬ ì „ì— ë°œì‚¬ëœ ì„±ê°„ ì—¬ê°ì„ ì…ë‹ˆë‹¤. ê±°ì˜ 13,000ëª…ì˜ ìŠ¹ê°ì„ íƒœìš´ ì´ ë°°ëŠ” íƒœì–‘ê³„ì—ì„œ ì˜¨ ì´ë¯¼ìë“¤ì„ ê·¼ì²˜ì˜ ë³„ ì£¼ìœ„ë¥¼ ë„ëŠ” ì„¸ ê°œì˜ ìƒˆë¡œì´ ê±°ì£¼í•  ìˆ˜ ìˆëŠ” ì™¸ê³„ í–‰ì„±ìœ¼ë¡œ ì‹¤ì–´ ë‚˜ë¥´ëŠ” ì²˜ë…€ í•­í•´ë¥¼ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. . ì²« ë²ˆì§¸ ëª©ì ì§€ì¸ 55í˜¸ ì•”í¬ë¦¬ Eë¡œ ì•ŒíŒŒ ì„¼íƒ€ìš°ë¦¬ë¥¼ ë„ëŠ” ë™ì•ˆ, ì¡°ì‹¬ì„±ì´ ì—†ëŠ” ìš°ì£¼ì„  íƒ€ì´íƒ€ë‹‰ì€ ë¨¼ì§€ êµ¬ë¦„ ì†ì— ìˆ¨ê²¨ì§„ ì‹œê³µê°„ ë³€ì¹™ê³¼ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤. ì•ˆíƒ€ê¹ê²Œë„, ê·¸ê²ƒì€ 1000ë…„ ì „ì˜ ì´ë¦„ê³¼ ë¹„ìŠ·í•œ ìš´ëª…ì„ ë§Œë‚¬ìŠµë‹ˆë‹¤. ë¹„ë¡ ê·¸ ë°°ëŠ” ì˜¨ì „í•˜ê²Œ ìœ ì§€ë˜ì—ˆì§€ë§Œ, ê±°ì˜ ì ˆë°˜ì˜ ìŠ¹ê°ë“¤ì€ ë‹¤ë¥¸ ì°¨ì›ìœ¼ë¡œ ì˜®ê²¨ì¡ŒìŠµë‹ˆë‹¤! . ìŠ¹ë¬´ì›ì„ êµ¬ì¡°í•˜ê³  ìƒì–´ë²„ë¦° ìŠ¹ê°ì„ ë˜ì°¾ëŠ” ê²ƒì„ ë•ê¸° ìœ„í•´, ì—¬ëŸ¬ë¶„ì€ ìš°ì£¼ì„ ì˜ ì†ìƒëœ ì»´í“¨í„° ì‹œìŠ¤í…œì—ì„œ ë³µêµ¬ëœ ê¸°ë¡ì„ ì‚¬ìš©í•˜ì—¬ ì–´ë–¤ ìŠ¹ê°ë“¤ì´ ì´ìƒ í˜„ìƒì— ì˜í•´ ì´ì†¡ë˜ì—ˆëŠ”ì§€ ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤. . ê·¸ë“¤ì„ êµ¬í•˜ê³  ì—­ì‚¬ë¥¼ ë°”ê¾¸ë„ë¡ ë„ì™€ì£¼ì„¸ìš”! . &lt;/br&gt; . &#128212;&#53076;&#46300;&#48513; . train.csv - ìŠ¹ê°ì˜ ì•½ 3ë¶„ì˜ 2(~8700)ì— ëŒ€í•œ ê°œì¸ ê¸°ë¡ . PassengerId - ê° ìŠ¹ê°ì˜ ê³ ìœ  ID. ê° IdëŠ” ggg_pp í˜•ì‹ì„ ì·¨í•¨ gggg: ìŠ¹ê°ê³¼ í•¨ê»˜ ì—¬í–‰í•˜ëŠ” ê·¸ë£¹ | pp: ê·¸ë£¹ ë‚´ ìŠ¹ê°ì˜ ë²ˆí˜¸ | ê·¸ë£¹ì˜ ì‚¬ëŒë“¤ì€ ê°€ì¡± êµ¬ì„±ì› ë˜ëŠ” ì•„ë‹ ìˆ˜ ìˆìŒ | . | HomePlanet - ìŠ¹ê°ì´ ì¶œë°œí•œ í–‰ì„±, ì¼ë°˜ì ìœ¼ë¡œ ì˜êµ¬ ê±°ì£¼ì§€ì˜ í–‰ì„± | CryoSleep - ìŠ¹ê°ì´ í•­í•´ ì¤‘ ê°€ì‚¬ìƒíƒœë¡œ ì„ ì¶œë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ ê·¹ì €ì˜¨ ìˆ˜ë©´ ì¤‘ì¸ ìŠ¹ê°ë“¤ì€ ê°ì‹¤ì— ê°‡í˜€ ìˆìŒ | . | Cabin - ê°ì‹¤ ë²ˆí˜¸(deck/num/side) side: Portì˜ ê²½ìš° P, Starboardì˜ ê²½ìš° S | . | Destination - ìŠ¹ê°ì´ ë‚´ë¦´ í–‰ì„ ì§€ | Age - ìŠ¹ê°ì˜ ì—°ë ¹ | VIP - ìŠ¹ê°ì´ í•­í•´ ì¤‘ íŠ¹ë³„ VIP ì„œë¹„ìŠ¤ ë¹„ìš©ì„ ì§€ë¶ˆí–ˆëŠ”ì§€ ì—¬ë¶€ | RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - ìŠ¹ê°ë“¤ì´ ìš°ì£¼ì„  íƒ€ì´íƒ€ë‹‰ì˜ ë§ì€ ê³ ê¸‰ í¸ì˜ì‹œì„¤ ê°ê°ì— ì²­êµ¬í•œ ê¸ˆì•¡ | Name - ìŠ¹ê°ì˜ ì´ë¦„ | Transported - ìŠ¹ê°ì´ ë‹¤ë¥¸ ì°¨ì›ìœ¼ë¡œ ìš´ì†¡ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€, targetê°’ | . test.csv - ë‚¨ì€ ìŠ¹ê°ì˜ 1/3(ì•½ 4300ëª…)ì— ëŒ€í•œ ê°œì¸ ê¸°ë¡ . - ìŠ¹ê°ì— ëŒ€í•œ Transported ê°’ì„ ì˜ˆì¸¡ . [ì¶œì²˜] Spaceship Titanic . Step 1. Imports . import numpy as np import pandas as pd import seaborn as sns import plotly.express as px import matplotlib.pyplot as plt import plotly.graph_objects as go from plotly.subplots import make_subplots from sklearn.impute import SimpleImputer # ê²°ì¸¡ì¹˜ ëŒ€ì²´ from sklearn.metrics import accuracy_score from sklearn.preprocessing import LabelEncoder from sklearn.model_selection import StratifiedKFold, train_test_split from lightgbm import LGBMClassifier import time import warnings warnings.filterwarnings(&#39;ignore&#39;) . Step 2. Data Loading and Preperation . train = pd.read_csv(&#39;data/train.csv&#39;) test = pd.read_csv(&#39;data/test.csv&#39;) submission = pd.read_csv(&#39;data/sample_submission.csv&#39;) RANDOM_STATE = 12 FOLDS = 5 STRATEGE = &#39;median&#39; . Exploring Train Data . 14ê°œì˜ ì—´ê³¼ 8693ê°œì˜ í–‰ì´ë‹¤. | 2324ê°œì˜ ê²°ì¸¡ê°’ì„ í¬í•¨í•œ 119378ê°œì˜ ê´€ì¸¡ê°’ì´ ìˆë‹¤. | 12ê°œì˜ ì—´ì€ ëª¨ë‘ ê²°ì¸¡ê°’ì´ ìˆê³  CryoSleepì´ ê²°ì¸¡ê°’ì€ 217ê°œë¡œ ê°€ì¥ ë§ë‹¤. | TransportedëŠ” train datasetì—ë§Œ ìˆëŠ” targetì´ë‹¤. | . Quick View of Train Data . Below are the first 5 rows of train dataset: . display(train.head()) print(f&quot; 33[92mtrain dataì˜ í–‰ ê°œìˆ˜: {train.shape[0]}&quot;) print(f&quot;train dataì˜ ì—´ ê°œìˆ˜: {train.shape[1]}&quot;) print(f&quot;train dataì˜ ê´€ì¸¡ê°’: {train.count().sum()}&quot;) print(f&quot;train dataì˜ ê²°ì¸¡ê°’: {train.isna().sum().sum()}&quot;) . PassengerId HomePlanet CryoSleep Cabin Destination Age VIP RoomService FoodCourt ShoppingMall Spa VRDeck Name Transported . 0 0001_01 | Europa | False | B/0/P | TRAPPIST-1e | 39.0 | False | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | Maham Ofracculy | False | . 1 0002_01 | Earth | False | F/0/S | TRAPPIST-1e | 24.0 | False | 109.0 | 9.0 | 25.0 | 549.0 | 44.0 | Juanna Vines | True | . 2 0003_01 | Europa | False | A/0/S | TRAPPIST-1e | 58.0 | True | 43.0 | 3576.0 | 0.0 | 6715.0 | 49.0 | Altark Susent | False | . 3 0003_02 | Europa | False | A/0/S | TRAPPIST-1e | 33.0 | False | 0.0 | 1283.0 | 371.0 | 3329.0 | 193.0 | Solam Susent | False | . 4 0004_01 | Earth | False | F/1/S | TRAPPIST-1e | 16.0 | False | 303.0 | 70.0 | 151.0 | 565.0 | 2.0 | Willy Santantines | True | . train dataì˜ í–‰ ê°œìˆ˜: 8693 train dataì˜ ì—´ ê°œìˆ˜: 14 train dataì˜ ê´€ì¸¡ê°’: 119378 train dataì˜ ê²°ì¸¡ê°’: 2324 . Column Wise missing values : . print(f&#39; 33[92m&#39;) print(train.isna().sum().sort_values(ascending = False)) . CryoSleep 217 ShoppingMall 208 VIP 203 HomePlanet 201 Name 200 Cabin 199 VRDeck 188 FoodCourt 183 Spa 183 Destination 182 RoomService 181 Age 179 PassengerId 0 Transported 0 dtype: int64 . Basic statistics of training data: . train.describe().T . count mean std min 25% 50% 75% max . Age 8514.0 | 28.827930 | 14.489021 | 0.0 | 19.0 | 27.0 | 38.0 | 79.0 | . RoomService 8512.0 | 224.687617 | 666.717663 | 0.0 | 0.0 | 0.0 | 47.0 | 14327.0 | . FoodCourt 8510.0 | 458.077203 | 1611.489240 | 0.0 | 0.0 | 0.0 | 76.0 | 29813.0 | . ShoppingMall 8485.0 | 173.729169 | 604.696458 | 0.0 | 0.0 | 0.0 | 27.0 | 23492.0 | . Spa 8510.0 | 311.138778 | 1136.705535 | 0.0 | 0.0 | 0.0 | 59.0 | 22408.0 | . VRDeck 8505.0 | 304.854791 | 1145.717189 | 0.0 | 0.0 | 0.0 | 46.0 | 24133.0 | . Exploring Test Data . Quick View of Test Data . Below are the first 5 rows of test dataset: . display(test.head()) print(f&quot; 33[92mtest dataì˜ í–‰ ê°œìˆ˜: {test.shape[0]}&quot;) print(f&quot;test dataì˜ ì—´ ê°œìˆ˜: {test.shape[1]}&quot;) print(f&quot;test dataì˜ ê´€ì¸¡ê°’: {test.count().sum()}&quot;) print(f&quot;test dataì˜ ê²°ì¸¡ê°’: {test.isna().sum().sum()}&quot;) . PassengerId HomePlanet CryoSleep Cabin Destination Age VIP RoomService FoodCourt ShoppingMall Spa VRDeck Name . 0 0013_01 | Earth | True | G/3/S | TRAPPIST-1e | 27.0 | False | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | Nelly Carsoning | . 1 0018_01 | Earth | False | F/4/S | TRAPPIST-1e | 19.0 | False | 0.0 | 9.0 | 0.0 | 2823.0 | 0.0 | Lerome Peckers | . 2 0019_01 | Europa | True | C/0/S | 55 Cancri e | 31.0 | False | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | Sabih Unhearfus | . 3 0021_01 | Europa | False | C/1/S | TRAPPIST-1e | 38.0 | False | 0.0 | 6652.0 | 0.0 | 181.0 | 585.0 | Meratz Caltilter | . 4 0023_01 | Earth | False | F/5/S | TRAPPIST-1e | 20.0 | False | 10.0 | 0.0 | 635.0 | 0.0 | 0.0 | Brence Harperez | . test dataì˜ í–‰ ê°œìˆ˜: 4277 test dataì˜ ì—´ ê°œìˆ˜: 13 test dataì˜ ê´€ì¸¡ê°’: 54484 test dataì˜ ê²°ì¸¡ê°’: 1117 . Column Wise missing values : . print(f&#39; 33[92m&#39;) print(test.isna().sum().sort_values(ascending = False)) . FoodCourt 106 Spa 101 Cabin 100 ShoppingMall 98 Name 94 CryoSleep 93 VIP 93 Destination 92 Age 91 HomePlanet 87 RoomService 82 VRDeck 80 PassengerId 0 dtype: int64 . Basic statistics of training data: . test.describe().T . count mean std min 25% 50% 75% max . Age 4186.0 | 28.658146 | 14.179072 | 0.0 | 19.0 | 26.0 | 37.0 | 79.0 | . RoomService 4195.0 | 219.266269 | 607.011289 | 0.0 | 0.0 | 0.0 | 53.0 | 11567.0 | . FoodCourt 4171.0 | 439.484296 | 1527.663045 | 0.0 | 0.0 | 0.0 | 78.0 | 25273.0 | . ShoppingMall 4179.0 | 177.295525 | 560.821123 | 0.0 | 0.0 | 0.0 | 33.0 | 8292.0 | . Spa 4176.0 | 303.052443 | 1117.186015 | 0.0 | 0.0 | 0.0 | 50.0 | 19844.0 | . VRDeck 4197.0 | 310.710031 | 1246.994742 | 0.0 | 0.0 | 0.0 | 36.0 | 22272.0 | . Quick View of Submission Data . submission.head() . PassengerId Transported . 0 0013_01 | False | . 1 0018_01 | False | . 2 0019_01 | False | . 3 0021_01 | False | . 4 0023_01 | False | . Step 3. EDA . Overview of Data . train = train.drop([&quot;PassengerId&quot;], axis=1) test = test.drop([&quot;PassengerId&quot;], axis=1) TARGET = &#39;Transported&#39; FEATURES = [col for col in train.columns if col != TARGET] RANDOM_STATE = 12 . train.iloc[:, :-1].describe().T.sort_values(by=&#39;std&#39;, ascending=False) .style.background_gradient(cmap=&#39;GnBu&#39;) .bar(subset=[&quot;max&quot;], color=&#39;#BB0000&#39;) .bar(subset=[&quot;mean&quot;,], color=&#39;green&#39;) . &nbsp; count mean std min 25% 50% 75% max . FoodCourt 8510.000000 | 458.077203 | 1611.489240 | 0.000000 | 0.000000 | 0.000000 | 76.000000 | 29813.000000 | . VRDeck 8505.000000 | 304.854791 | 1145.717189 | 0.000000 | 0.000000 | 0.000000 | 46.000000 | 24133.000000 | . Spa 8510.000000 | 311.138778 | 1136.705535 | 0.000000 | 0.000000 | 0.000000 | 59.000000 | 22408.000000 | . RoomService 8512.000000 | 224.687617 | 666.717663 | 0.000000 | 0.000000 | 0.000000 | 47.000000 | 14327.000000 | . ShoppingMall 8485.000000 | 173.729169 | 604.696458 | 0.000000 | 0.000000 | 0.000000 | 27.000000 | 23492.000000 | . Age 8514.000000 | 28.827930 | 14.489021 | 0.000000 | 19.000000 | 27.000000 | 38.000000 | 79.000000 | . Null Value Distribution . &#128204; Observations in Null Value Distribution : . í–‰ì˜ ê²°ì¸¡ê°’ì˜ ìµœëŒ€ê°’ì€ 3ì´ë©° ê°€ì¥ ë‚®ì€ ê°’ì€ ê²°ì¸¡ê°’ì´ ì•„ë‹™ë‹ˆë‹¤. | í¥ë¯¸ë¡­ê²Œë„, ê²°ì¸¡ê°’ ë¶„í¬(í–‰ ê¸°ì¤€)ëŠ” trainì™€ test dataset ê°„ì— ìƒë‹¹íˆ ë™ì¼í•©ë‹ˆë‹¤. | ê²°ì¸¡ê°’ì´ ì—†ëŠ” ê´€ì¸¡ì¹˜(í–‰ ê¸°ì¤€)ëŠ” ì•½ 76%ì…ë‹ˆë‹¤. | ë‚˜ë¨¸ì§€ ê´€ì¸¡ì¹˜ì˜ 24%(í–‰ ê¸°ì¤€)ëŠ” ê²°ì¸¡ê°’ì´ 1-3ê°œì…ë‹ˆë‹¤ | . Column wise Null Value Distribution . train_null = pd.DataFrame(train.isna().sum()).sort_values(by=0 ,ascending=False)[:-1] display(train_null) test_null = pd.DataFrame(test.isna().sum()).sort_values(by=0 ,ascending=False) display(test_null) . 0 . CryoSleep 217 | . ShoppingMall 208 | . VIP 203 | . HomePlanet 201 | . Name 200 | . Cabin 199 | . VRDeck 188 | . FoodCourt 183 | . Spa 183 | . Destination 182 | . RoomService 181 | . Age 179 | . 0 . FoodCourt 106 | . Spa 101 | . Cabin 100 | . ShoppingMall 98 | . Name 94 | . CryoSleep 93 | . VIP 93 | . Destination 92 | . Age 91 | . HomePlanet 87 | . RoomService 82 | . VRDeck 80 | . fig = make_subplots(rows=1, cols=2, column_titles = [&quot;Train Data&quot;, &quot;Test Data&quot;] , x_title=&quot;Missing Values&quot;) fig.add_trace(go.Bar(x=train_null[0], y=train_null.index, orientation=&quot;h&quot;, marker=dict(color=[n for n in range(12)], line_color=&#39;rgb(0,0,0)&#39; , line_width = 2, coloraxis=&quot;coloraxis&quot;)), 1, 1) fig.add_trace(go.Bar(x=test_null[0], y=test_null.index, orientation=&quot;h&quot;, marker=dict(color=[n for n in range(12)], line_color=&#39;rgb(0,0,0)&#39;, line_width = 2, coloraxis=&quot;coloraxis&quot;)), 1, 2) fig.update_layout(showlegend=False, title_text=&quot;Column wise Null Value Distribution&quot;, title_x=0.5) . missing_train_row = train.isna().sum(axis=1) missing_train_row = pd.DataFrame(missing_train_row.value_counts()/train.shape[0]).reset_index() missing_test_row = test.isna().sum(axis=1) missing_test_row = pd.DataFrame(missing_test_row.value_counts()/test.shape[0]).reset_index() . missing_train_row.columns = [&#39;no&#39;, &#39;count&#39;] missing_test_row.columns = [&#39;no&#39;, &#39;count&#39;] missing_train_row[&quot;count&quot;] = missing_train_row[&quot;count&quot;]*100 missing_test_row[&quot;count&quot;] = missing_test_row[&quot;count&quot;]*100 fig = make_subplots(rows=1, cols=2, column_titles = [&quot;Train Data&quot;, &quot;Test Data&quot;] , x_title=&quot;Missing Values&quot;,) fig.add_trace(go.Bar(x=missing_train_row[&quot;no&quot;], y=missing_train_row[&quot;count&quot;] , marker=dict(color=[n for n in range(4)], line_color=&#39;rgb(0,0,0)&#39; , line_width = 3 ,coloraxis=&quot;coloraxis&quot;)), 1, 1) fig.add_trace(go.Bar(x= missing_test_row[&quot;no&quot;], y=missing_test_row[&quot;count&quot;], marker=dict(color=[n for n in range(4)], line_color=&#39;rgb(0,0,0)&#39;, line_width = 3 , coloraxis=&quot;coloraxis&quot;)), 1, 2) fig.update_layout(showlegend=False, title_text=&quot;Row wise Null Value Distribution&quot;, title_x=0.5) . &#128204; Observations in Continuos and Categorical Data Distribution : . 12ê°œ í”¼ì²˜ ì¤‘ 6ê°œì˜ í”¼ì²˜ëŠ” ì—°ì†í˜•, 2ê°œì˜ í”¼ì²˜ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°, 4ê°œì˜ í”¼ì²˜ëŠ” ë²”ì£¼í˜•ì…ë‹ˆë‹¤. | HomePlanetê³¼ Destinationì—ëŠ” ì„¸ ê°€ì§€ ê³ ìœ í•œ ê°’ì´ ìˆìŠµë‹ˆë‹¤. | CryoSleepê³¼ VIPëŠ” bool type ì…ë‹ˆë‹¤. | . _ = train.hist(figsize=(12, 8), bins=50) . df = pd.concat([train[FEATURES], test[FEATURES]], axis=0) text_features = [&quot;Cabin&quot;, &quot;Name&quot;] # [&#39;HomePlanet&#39;, &#39;CryoSleep&#39;, &#39;Destination&#39;, &#39;VIP&#39;] cat_features = [col for col in FEATURES if df[col].nunique() &lt; 25 and col not in text_features] # [&#39;Age&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;] cont_features = [col for col in FEATURES if df[col].nunique() &gt;= 25 and col not in text_features] del df . print(f&#39; 33[92mTotal number of features: {len(FEATURES)}&#39;) print(f&#39; 33[92mNumber of categorical features: {len(cat_features)}&#39;) print(f&#39; 33[92mNumber of continuos features: {len(cont_features)}&#39;) print(f&#39; 33[92mNumber of text features: {len(text_features)}&#39;) . Total number of features: 12 Number of categorical features: 4 Number of continuos features: 6 Number of text features: 2 . labels=[&#39;Categorical&#39;, &#39;Continuos&#39;, &quot;Text&quot;] values= [len(cat_features), len(cont_features), len(text_features)] colors = [&#39;#DE3163&#39;, &#39;#58D68D&#39;] fig = go.Figure(data=[go.Pie( labels=labels, values=values, pull=[0.1, 0, 0 ], marker=dict(colors=colors, line=dict(color=&#39;#000000&#39;, width=2)) )]) fig.show() . Distribution of Age . train_age = train.copy() test_age = test.copy() train_age[&quot;type&quot;] = &quot;Train&quot; test_age[&quot;type&quot;] = &quot;Test&quot; ageDf = pd.concat([train_age, test_age]) fig = px.histogram(data_frame=ageDf, x=&quot;Age&quot;, color= &quot;type&quot;, color_discrete_sequence=[&#39;#58D68D&#39;,&#39;#DE3163&#39;], marginal=&quot;box&quot;, nbins= 100, template=&quot;plotly_white&quot; ) fig.update_layout(title = &quot;Distribution of Age&quot; , title_x = 0.5) fig.show() . Feature Distribution of Continous Features . if len(cat_features) == 0 : print(&quot;No Categorical features&quot;) else: ncols = 2 nrows = 2 fig, axes = plt.subplots(nrows, ncols, figsize=(18, 10)) for r in range(nrows): for c in range(ncols): col = cat_features[r*ncols+c] sns.countplot(train[col], ax=axes[r,c] ,palette=&quot;viridis&quot;, label=&#39;Train data&#39;) sns.countplot(test[col], ax=axes[r,c] ,palette=&quot;magma&quot;, label=&#39;Test data&#39;) axes[r,c].legend() axes[r,c].set_ylabel(&#39;&#39;) axes[r,c].set_xlabel(col, fontsize=20) axes[r,c].tick_params(labelsize=10, width=0.5) axes[r,c].xaxis.offsetText.set_fontsize(4) axes[r,c].yaxis.offsetText.set_fontsize(4) plt.show() . Target Distribution . ğŸ“Œ Observations in Target Distribution : . Targetì˜ ê°’ì€ 0ê³¼ 1ì´ë‹¤. | 0ê³¼ 1ì€ ê±°ì˜ ë™ë“±í•œ ë¶„í¬ë‹¤. | . target_df = pd.DataFrame(train[TARGET].value_counts()).reset_index() target_df.columns = [TARGET, &#39;count&#39;] print(&quot; 33[94mPercentage of Transported = 0: {:.2f} %&quot;.format(target_df[&quot;count&quot;][0]*100 / train.shape[0])) print(&quot; 33[94mPercentage of Transported = 1: {:.2f} %&quot;.format(target_df[&quot;count&quot;][1]*100 / train.shape[0])) . Percentage of Transported = 0: 50.36 % Percentage of Transported = 1: 49.64 % . Correlation Metrix . fig = px.imshow(train.corr(), text_auto=True, aspect=&quot;auto&quot;, color_continuous_scale = &quot;brwnyl&quot;) fig.show() . Step 4. Data Pre-Processing . Imputing Missing Values . [ì°¸ê³ ] sklearn SimpleImputer . cont_features . [&#39;Age&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;] . imputer_cols = [&quot;Age&quot;, &quot;FoodCourt&quot;, &quot;ShoppingMall&quot;, &quot;Spa&quot;, &quot;VRDeck&quot; ,&quot;RoomService&quot;] imputer = SimpleImputer(strategy=&#39;median&#39;) imputer.fit(train[imputer_cols]) . SimpleImputer(strategy=&#39;median&#39;) . train[imputer_cols] = imputer.transform(train[imputer_cols]) test[imputer_cols] = imputer.transform(test[imputer_cols]) . ğŸªplanet Z... . train[&quot;HomePlanet&quot;] = train[&quot;HomePlanet&quot;].fillna(&#39;Z&#39;) test[&quot;HomePlanet&quot;] = test[&quot;HomePlanet&quot;].fillna(&#39;Z&#39;) . Encoding Categorical Features . text_features . [&#39;Cabin&#39;, &#39;Name&#39;] . cat_features . [&#39;HomePlanet&#39;, &#39;CryoSleep&#39;, &#39;Destination&#39;, &#39;VIP&#39;] . # def labelEncoder(data, columns): # for col in columns: # labels = [] # l_encoder = LabelEncoder() # items = data[col] # l_encoder.fit(items) # labels = l_encoder.transform(items) # data[col] = labels # le_name_mapping = dict(zip(l_encoder.classes_, l_encoder.transform(l_encoder.classes_))) # print(le_name_mapping) . . label_cols = [&quot;HomePlanet&quot;, &quot;CryoSleep&quot;,&quot;Cabin&quot;, &quot;Destination&quot; ,&quot;VIP&quot;] def label_encoder(train, test, columns): for col in columns: train[col] = train[col].astype(str) test[col] = test[col].astype(str) train[col] = LabelEncoder().fit_transform(train[col]) test[col] = LabelEncoder().fit_transform(test[col]) return train, test train, test = label_encoder(train, test ,label_cols) . train.drop([&quot;Name&quot; ,&quot;Cabin&quot;] , axis = 1 ,inplace = True) test.drop([&quot;Name&quot; ,&quot;Cabin&quot;] , axis = 1 ,inplace = True) X = train.drop(TARGET , axis =1 ) y = train[TARGET] X_train , X_test , y_train , y_test = train_test_split(X , y, random_state = 12 , test_size =0.33) . Step 5. Modeling . lgb_params = { &#39;objective&#39; : &#39;binary&#39;, &#39;n_estimators&#39; :50, &#39;learning_rate&#39; : 0.08 } lgb_predictions = 0 lgb_scores = [] lgb_fimp = [] LGBM_FEATURES = list(train.columns)[:-1] skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE) for fold, (train_idx, valid_idx) in enumerate(skf.split(train[LGBM_FEATURES], train[TARGET])): print(f&#39; 033[94m&#39;) print(10*&quot;=&quot;, f&quot;Fold={fold+1}&quot;, 10*&quot;=&quot;) start_time = time.time() X_train, X_valid = train.iloc[train_idx][LGBM_FEATURES], train.iloc[valid_idx][LGBM_FEATURES] y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx] model = LGBMClassifier(**lgb_params) model.fit(X_train, y_train,verbose=0) preds_valid = model.predict(X_valid) acc = accuracy_score(y_valid, preds_valid) lgb_scores.append(acc) run_time = time.time() - start_time fim = pd.DataFrame(index=LGBM_FEATURES, data=model.feature_importances_, columns=[f&#39;{fold}_importance&#39;]) lgb_fimp.append(fim) print(f&quot;Fold={fold+1}, Accuracy score: {acc:.2f}%, Run Time: {run_time:.2f}s&quot;) test_preds = model.predict(test[LGBM_FEATURES]) lgb_predictions += test_preds/FOLDS print(&quot;&quot;) print(&quot;Mean Accuracy :&quot;, np.mean(lgb_scores)) . ========== Fold=1 ========== Fold=1, Accuracy score: 0.81%, Run Time: 4.06s ========== Fold=2 ========== Fold=2, Accuracy score: 0.78%, Run Time: 1.70s ========== Fold=3 ========== Fold=3, Accuracy score: 0.79%, Run Time: 0.74s ========== Fold=4 ========== Fold=4, Accuracy score: 0.79%, Run Time: 0.11s ========== Fold=5 ========== Fold=5, Accuracy score: 0.81%, Run Time: 0.21s Mean Accuracy : 0.7958136330880743 . lgbm_fis_df = pd.concat(lgb_fimp, axis=1).head(15) lgbm_fis_df.sort_values(&#39;1_importance&#39;).plot(kind=&#39;barh&#39;, figsize=(15, 10), title=&#39;Feature Importance Across Folds&#39;) plt.show() . Step 6. Submission . submission[TARGET] = lgb_predictions.astype(&quot;bool&quot;) submission.to_csv(&quot;submission.csv&quot;,index=False) submission.head() . PassengerId Transported . 0 0013_01 | True | . 1 0018_01 | False | . 2 0019_01 | True | . 3 0021_01 | True | . 4 0023_01 | True | .",
            "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/kaggle/ml/2022/07/07/_07_08_Spaceship_Titanic_%ED%95%84%EC%82%AC.html",
            "relUrl": "/kaggle/ml/2022/07/07/_07_08_Spaceship_Titanic_%ED%95%84%EC%82%AC.html",
            "date": " â€¢ Jul 7, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.â†© . 2. This is the other footnote. You can even have a link!â†© .",
            "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " â€¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a â€œlevel 1 headingâ€ in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Hereâ€™s a footnote 1. Hereâ€™s a horizontal rule: . . Lists . Hereâ€™s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes â€¦andâ€¦ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.Â &#8617; . |",
            "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " â€¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.Â &#8617; . |",
          "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ â€œsitemap.xmlâ€ | absolute_url }} | .",
          "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}