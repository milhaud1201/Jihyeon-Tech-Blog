{
  
    
        "post0": {
            "title": "[kaggle] Spaceship Titanic 필사",
            "content": "Spaceship Titanic . &#128675;&#8205;&#9794;&#65039;&#47785;&#51201; . 우주선 타이타닉 어떤 승객이 다른 차원으로 이동할지 예측 . &lt;/br&gt; . &#129513;&#53945;&#51669; . 우주 미스터리를 풀기 위해 여러분의 데이터 과학 기술이 필요한 2912년에 오신 것을 환영합니다. 4광년 떨어진 곳에서 전송이 왔는데 상황이 좋지 않아요 . 우주선 타이타닉은 한 달 전에 발사된 성간 여객선입니다. 거의 13,000명의 승객을 태운 이 배는 태양계에서 온 이민자들을 근처의 별 주위를 도는 세 개의 새로이 거주할 수 있는 외계 행성으로 실어 나르는 처녀 항해를 시작했습니다. . 첫 번째 목적지인 55호 암크리 E로 알파 센타우리를 도는 동안, 조심성이 없는 우주선 타이타닉은 먼지 구름 속에 숨겨진 시공간 변칙과 충돌했습니다. 안타깝게도, 그것은 1000년 전의 이름과 비슷한 운명을 만났습니다. 비록 그 배는 온전하게 유지되었지만, 거의 절반의 승객들은 다른 차원으로 옮겨졌습니다! . 승무원을 구조하고 잃어버린 승객을 되찾는 것을 돕기 위해, 여러분은 우주선의 손상된 컴퓨터 시스템에서 복구된 기록을 사용하여 어떤 승객들이 이상 현상에 의해 이송되었는지 예측해야 합니다. . 그들을 구하고 역사를 바꾸도록 도와주세요! . &lt;/br&gt; . &#128212;&#53076;&#46300;&#48513; . train.csv - 승객의 약 3분의 2(~8700)에 대한 개인 기록 . PassengerId - 각 승객의 고유 ID. 각 Id는 ggg_pp 형식을 취함 gggg: 승객과 함께 여행하는 그룹 | pp: 그룹 내 승객의 번호 | 그룹의 사람들은 가족 구성원 또는 아닐 수 있음 | . | HomePlanet - 승객이 출발한 행성, 일반적으로 영구 거주지의 행성 | CryoSleep - 승객이 항해 중 가사상태로 선출되었는지 여부 극저온 수면 중인 승객들은 객실에 갇혀 있음 | . | Cabin - 객실 번호(deck/num/side) side: Port의 경우 P, Starboard의 경우 S | . | Destination - 승객이 내릴 행선지 | Age - 승객의 연령 | VIP - 승객이 항해 중 특별 VIP 서비스 비용을 지불했는지 여부 | RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - 승객들이 우주선 타이타닉의 많은 고급 편의시설 각각에 청구한 금액 | Name - 승객의 이름 | Transported - 승객이 다른 차원으로 운송되었는지 여부, target값 | . test.csv - 남은 승객의 1/3(약 4300명)에 대한 개인 기록 . - 승객에 대한 Transported 값을 예측 . [출처] Spaceship Titanic . Step 1. Imports . import numpy as np import pandas as pd import seaborn as sns import plotly.express as px import matplotlib.pyplot as plt import plotly.graph_objects as go from plotly.subplots import make_subplots from sklearn.impute import SimpleImputer # 결측치 대체 from sklearn.metrics import accuracy_score from sklearn.preprocessing import LabelEncoder from sklearn.model_selection import StratifiedKFold, train_test_split from lightgbm import LGBMClassifier import time import warnings warnings.filterwarnings(&#39;ignore&#39;) . Step 2. Data Loading and Preperation . train = pd.read_csv(&#39;data/train.csv&#39;) test = pd.read_csv(&#39;data/test.csv&#39;) submission = pd.read_csv(&#39;data/sample_submission.csv&#39;) RANDOM_STATE = 12 FOLDS = 5 STRATEGE = &#39;median&#39; . Exploring Train Data . 14개의 열과 8693개의 행이다. | 2324개의 결측값을 포함한 119378개의 관측값이 있다. | 12개의 열은 모두 결측값이 있고 CryoSleep이 결측값은 217개로 가장 많다. | Transported는 train dataset에만 있는 target이다. | . Quick View of Train Data . Below are the first 5 rows of train dataset: . display(train.head()) print(f&quot; 33[92mtrain data의 행 개수: {train.shape[0]}&quot;) print(f&quot;train data의 열 개수: {train.shape[1]}&quot;) print(f&quot;train data의 관측값: {train.count().sum()}&quot;) print(f&quot;train data의 결측값: {train.isna().sum().sum()}&quot;) . PassengerId HomePlanet CryoSleep Cabin Destination Age VIP RoomService FoodCourt ShoppingMall Spa VRDeck Name Transported . 0 0001_01 | Europa | False | B/0/P | TRAPPIST-1e | 39.0 | False | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | Maham Ofracculy | False | . 1 0002_01 | Earth | False | F/0/S | TRAPPIST-1e | 24.0 | False | 109.0 | 9.0 | 25.0 | 549.0 | 44.0 | Juanna Vines | True | . 2 0003_01 | Europa | False | A/0/S | TRAPPIST-1e | 58.0 | True | 43.0 | 3576.0 | 0.0 | 6715.0 | 49.0 | Altark Susent | False | . 3 0003_02 | Europa | False | A/0/S | TRAPPIST-1e | 33.0 | False | 0.0 | 1283.0 | 371.0 | 3329.0 | 193.0 | Solam Susent | False | . 4 0004_01 | Earth | False | F/1/S | TRAPPIST-1e | 16.0 | False | 303.0 | 70.0 | 151.0 | 565.0 | 2.0 | Willy Santantines | True | . train data의 행 개수: 8693 train data의 열 개수: 14 train data의 관측값: 119378 train data의 결측값: 2324 . Column Wise missing values : . print(f&#39; 33[92m&#39;) print(train.isna().sum().sort_values(ascending = False)) . CryoSleep 217 ShoppingMall 208 VIP 203 HomePlanet 201 Name 200 Cabin 199 VRDeck 188 FoodCourt 183 Spa 183 Destination 182 RoomService 181 Age 179 PassengerId 0 Transported 0 dtype: int64 . Basic statistics of training data: . train.describe().T . count mean std min 25% 50% 75% max . Age 8514.0 | 28.827930 | 14.489021 | 0.0 | 19.0 | 27.0 | 38.0 | 79.0 | . RoomService 8512.0 | 224.687617 | 666.717663 | 0.0 | 0.0 | 0.0 | 47.0 | 14327.0 | . FoodCourt 8510.0 | 458.077203 | 1611.489240 | 0.0 | 0.0 | 0.0 | 76.0 | 29813.0 | . ShoppingMall 8485.0 | 173.729169 | 604.696458 | 0.0 | 0.0 | 0.0 | 27.0 | 23492.0 | . Spa 8510.0 | 311.138778 | 1136.705535 | 0.0 | 0.0 | 0.0 | 59.0 | 22408.0 | . VRDeck 8505.0 | 304.854791 | 1145.717189 | 0.0 | 0.0 | 0.0 | 46.0 | 24133.0 | . Exploring Test Data . Quick View of Test Data . Below are the first 5 rows of test dataset: . display(test.head()) print(f&quot; 33[92mtest data의 행 개수: {test.shape[0]}&quot;) print(f&quot;test data의 열 개수: {test.shape[1]}&quot;) print(f&quot;test data의 관측값: {test.count().sum()}&quot;) print(f&quot;test data의 결측값: {test.isna().sum().sum()}&quot;) . PassengerId HomePlanet CryoSleep Cabin Destination Age VIP RoomService FoodCourt ShoppingMall Spa VRDeck Name . 0 0013_01 | Earth | True | G/3/S | TRAPPIST-1e | 27.0 | False | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | Nelly Carsoning | . 1 0018_01 | Earth | False | F/4/S | TRAPPIST-1e | 19.0 | False | 0.0 | 9.0 | 0.0 | 2823.0 | 0.0 | Lerome Peckers | . 2 0019_01 | Europa | True | C/0/S | 55 Cancri e | 31.0 | False | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | Sabih Unhearfus | . 3 0021_01 | Europa | False | C/1/S | TRAPPIST-1e | 38.0 | False | 0.0 | 6652.0 | 0.0 | 181.0 | 585.0 | Meratz Caltilter | . 4 0023_01 | Earth | False | F/5/S | TRAPPIST-1e | 20.0 | False | 10.0 | 0.0 | 635.0 | 0.0 | 0.0 | Brence Harperez | . test data의 행 개수: 4277 test data의 열 개수: 13 test data의 관측값: 54484 test data의 결측값: 1117 . Column Wise missing values : . print(f&#39; 33[92m&#39;) print(test.isna().sum().sort_values(ascending = False)) . FoodCourt 106 Spa 101 Cabin 100 ShoppingMall 98 Name 94 CryoSleep 93 VIP 93 Destination 92 Age 91 HomePlanet 87 RoomService 82 VRDeck 80 PassengerId 0 dtype: int64 . Basic statistics of training data: . test.describe().T . count mean std min 25% 50% 75% max . Age 4186.0 | 28.658146 | 14.179072 | 0.0 | 19.0 | 26.0 | 37.0 | 79.0 | . RoomService 4195.0 | 219.266269 | 607.011289 | 0.0 | 0.0 | 0.0 | 53.0 | 11567.0 | . FoodCourt 4171.0 | 439.484296 | 1527.663045 | 0.0 | 0.0 | 0.0 | 78.0 | 25273.0 | . ShoppingMall 4179.0 | 177.295525 | 560.821123 | 0.0 | 0.0 | 0.0 | 33.0 | 8292.0 | . Spa 4176.0 | 303.052443 | 1117.186015 | 0.0 | 0.0 | 0.0 | 50.0 | 19844.0 | . VRDeck 4197.0 | 310.710031 | 1246.994742 | 0.0 | 0.0 | 0.0 | 36.0 | 22272.0 | . Quick View of Submission Data . submission.head() . PassengerId Transported . 0 0013_01 | False | . 1 0018_01 | False | . 2 0019_01 | False | . 3 0021_01 | False | . 4 0023_01 | False | . Step 3. EDA . Overview of Data . train = train.drop([&quot;PassengerId&quot;], axis=1) test = test.drop([&quot;PassengerId&quot;], axis=1) TARGET = &#39;Transported&#39; FEATURES = [col for col in train.columns if col != TARGET] RANDOM_STATE = 12 . train.iloc[:, :-1].describe().T.sort_values(by=&#39;std&#39;, ascending=False) .style.background_gradient(cmap=&#39;GnBu&#39;) .bar(subset=[&quot;max&quot;], color=&#39;#BB0000&#39;) .bar(subset=[&quot;mean&quot;,], color=&#39;green&#39;) . &nbsp; count mean std min 25% 50% 75% max . FoodCourt 8510.000000 | 458.077203 | 1611.489240 | 0.000000 | 0.000000 | 0.000000 | 76.000000 | 29813.000000 | . VRDeck 8505.000000 | 304.854791 | 1145.717189 | 0.000000 | 0.000000 | 0.000000 | 46.000000 | 24133.000000 | . Spa 8510.000000 | 311.138778 | 1136.705535 | 0.000000 | 0.000000 | 0.000000 | 59.000000 | 22408.000000 | . RoomService 8512.000000 | 224.687617 | 666.717663 | 0.000000 | 0.000000 | 0.000000 | 47.000000 | 14327.000000 | . ShoppingMall 8485.000000 | 173.729169 | 604.696458 | 0.000000 | 0.000000 | 0.000000 | 27.000000 | 23492.000000 | . Age 8514.000000 | 28.827930 | 14.489021 | 0.000000 | 19.000000 | 27.000000 | 38.000000 | 79.000000 | . Null Value Distribution . &#128204; Observations in Null Value Distribution : . 행의 결측값의 최대값은 3이며 가장 낮은 값은 결측값이 아닙니다. | 흥미롭게도, 결측값 분포(행 기준)는 train와 test dataset 간에 상당히 동일합니다. | 결측값이 없는 관측치(행 기준)는 약 76%입니다. | 나머지 관측치의 24%(행 기준)는 결측값이 1-3개입니다 | . Column wise Null Value Distribution . train_null = pd.DataFrame(train.isna().sum()).sort_values(by=0 ,ascending=False)[:-1] display(train_null) test_null = pd.DataFrame(test.isna().sum()).sort_values(by=0 ,ascending=False) display(test_null) . 0 . CryoSleep 217 | . ShoppingMall 208 | . VIP 203 | . HomePlanet 201 | . Name 200 | . Cabin 199 | . VRDeck 188 | . FoodCourt 183 | . Spa 183 | . Destination 182 | . RoomService 181 | . Age 179 | . 0 . FoodCourt 106 | . Spa 101 | . Cabin 100 | . ShoppingMall 98 | . Name 94 | . CryoSleep 93 | . VIP 93 | . Destination 92 | . Age 91 | . HomePlanet 87 | . RoomService 82 | . VRDeck 80 | . fig = make_subplots(rows=1, cols=2, column_titles = [&quot;Train Data&quot;, &quot;Test Data&quot;] , x_title=&quot;Missing Values&quot;) fig.add_trace(go.Bar(x=train_null[0], y=train_null.index, orientation=&quot;h&quot;, marker=dict(color=[n for n in range(12)], line_color=&#39;rgb(0,0,0)&#39; , line_width = 2, coloraxis=&quot;coloraxis&quot;)), 1, 1) fig.add_trace(go.Bar(x=test_null[0], y=test_null.index, orientation=&quot;h&quot;, marker=dict(color=[n for n in range(12)], line_color=&#39;rgb(0,0,0)&#39;, line_width = 2, coloraxis=&quot;coloraxis&quot;)), 1, 2) fig.update_layout(showlegend=False, title_text=&quot;Column wise Null Value Distribution&quot;, title_x=0.5) . missing_train_row = train.isna().sum(axis=1) missing_train_row = pd.DataFrame(missing_train_row.value_counts()/train.shape[0]).reset_index() missing_test_row = test.isna().sum(axis=1) missing_test_row = pd.DataFrame(missing_test_row.value_counts()/test.shape[0]).reset_index() . missing_train_row.columns = [&#39;no&#39;, &#39;count&#39;] missing_test_row.columns = [&#39;no&#39;, &#39;count&#39;] missing_train_row[&quot;count&quot;] = missing_train_row[&quot;count&quot;]*100 missing_test_row[&quot;count&quot;] = missing_test_row[&quot;count&quot;]*100 fig = make_subplots(rows=1, cols=2, column_titles = [&quot;Train Data&quot;, &quot;Test Data&quot;] , x_title=&quot;Missing Values&quot;,) fig.add_trace(go.Bar(x=missing_train_row[&quot;no&quot;], y=missing_train_row[&quot;count&quot;] , marker=dict(color=[n for n in range(4)], line_color=&#39;rgb(0,0,0)&#39; , line_width = 3 ,coloraxis=&quot;coloraxis&quot;)), 1, 1) fig.add_trace(go.Bar(x= missing_test_row[&quot;no&quot;], y=missing_test_row[&quot;count&quot;], marker=dict(color=[n for n in range(4)], line_color=&#39;rgb(0,0,0)&#39;, line_width = 3 , coloraxis=&quot;coloraxis&quot;)), 1, 2) fig.update_layout(showlegend=False, title_text=&quot;Row wise Null Value Distribution&quot;, title_x=0.5) . &#128204; Observations in Continuos and Categorical Data Distribution : . 12개 피처 중 6개의 피처는 연속형, 2개의 피처는 텍스트 데이터, 4개의 피처는 범주형입니다. | HomePlanet과 Destination에는 세 가지 고유한 값이 있습니다. | CryoSleep과 VIP는 bool type 입니다. | . _ = train.hist(figsize=(12, 8), bins=50) . df = pd.concat([train[FEATURES], test[FEATURES]], axis=0) text_features = [&quot;Cabin&quot;, &quot;Name&quot;] # [&#39;HomePlanet&#39;, &#39;CryoSleep&#39;, &#39;Destination&#39;, &#39;VIP&#39;] cat_features = [col for col in FEATURES if df[col].nunique() &lt; 25 and col not in text_features] # [&#39;Age&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;] cont_features = [col for col in FEATURES if df[col].nunique() &gt;= 25 and col not in text_features] del df . print(f&#39; 33[92mTotal number of features: {len(FEATURES)}&#39;) print(f&#39; 33[92mNumber of categorical features: {len(cat_features)}&#39;) print(f&#39; 33[92mNumber of continuos features: {len(cont_features)}&#39;) print(f&#39; 33[92mNumber of text features: {len(text_features)}&#39;) . Total number of features: 12 Number of categorical features: 4 Number of continuos features: 6 Number of text features: 2 . labels=[&#39;Categorical&#39;, &#39;Continuos&#39;, &quot;Text&quot;] values= [len(cat_features), len(cont_features), len(text_features)] colors = [&#39;#DE3163&#39;, &#39;#58D68D&#39;] fig = go.Figure(data=[go.Pie( labels=labels, values=values, pull=[0.1, 0, 0 ], marker=dict(colors=colors, line=dict(color=&#39;#000000&#39;, width=2)) )]) fig.show() . Distribution of Age . train_age = train.copy() test_age = test.copy() train_age[&quot;type&quot;] = &quot;Train&quot; test_age[&quot;type&quot;] = &quot;Test&quot; ageDf = pd.concat([train_age, test_age]) fig = px.histogram(data_frame=ageDf, x=&quot;Age&quot;, color= &quot;type&quot;, color_discrete_sequence=[&#39;#58D68D&#39;,&#39;#DE3163&#39;], marginal=&quot;box&quot;, nbins= 100, template=&quot;plotly_white&quot; ) fig.update_layout(title = &quot;Distribution of Age&quot; , title_x = 0.5) fig.show() . Feature Distribution of Continous Features . if len(cat_features) == 0 : print(&quot;No Categorical features&quot;) else: ncols = 2 nrows = 2 fig, axes = plt.subplots(nrows, ncols, figsize=(18, 10)) for r in range(nrows): for c in range(ncols): col = cat_features[r*ncols+c] sns.countplot(train[col], ax=axes[r,c] ,palette=&quot;viridis&quot;, label=&#39;Train data&#39;) sns.countplot(test[col], ax=axes[r,c] ,palette=&quot;magma&quot;, label=&#39;Test data&#39;) axes[r,c].legend() axes[r,c].set_ylabel(&#39;&#39;) axes[r,c].set_xlabel(col, fontsize=20) axes[r,c].tick_params(labelsize=10, width=0.5) axes[r,c].xaxis.offsetText.set_fontsize(4) axes[r,c].yaxis.offsetText.set_fontsize(4) plt.show() . Target Distribution . 📌 Observations in Target Distribution : . Target의 값은 0과 1이다. | 0과 1은 거의 동등한 분포다. | . target_df = pd.DataFrame(train[TARGET].value_counts()).reset_index() target_df.columns = [TARGET, &#39;count&#39;] print(&quot; 33[94mPercentage of Transported = 0: {:.2f} %&quot;.format(target_df[&quot;count&quot;][0]*100 / train.shape[0])) print(&quot; 33[94mPercentage of Transported = 1: {:.2f} %&quot;.format(target_df[&quot;count&quot;][1]*100 / train.shape[0])) . Percentage of Transported = 0: 50.36 % Percentage of Transported = 1: 49.64 % . Correlation Metrix . fig = px.imshow(train.corr(), text_auto=True, aspect=&quot;auto&quot;, color_continuous_scale = &quot;brwnyl&quot;) fig.show() . Step 4. Data Pre-Processing . Imputing Missing Values . [참고] sklearn SimpleImputer . cont_features . [&#39;Age&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;] . imputer_cols = [&quot;Age&quot;, &quot;FoodCourt&quot;, &quot;ShoppingMall&quot;, &quot;Spa&quot;, &quot;VRDeck&quot; ,&quot;RoomService&quot;] imputer = SimpleImputer(strategy=&#39;median&#39;) imputer.fit(train[imputer_cols]) . SimpleImputer(strategy=&#39;median&#39;) . train[imputer_cols] = imputer.transform(train[imputer_cols]) test[imputer_cols] = imputer.transform(test[imputer_cols]) . 🪐planet Z... . train[&quot;HomePlanet&quot;] = train[&quot;HomePlanet&quot;].fillna(&#39;Z&#39;) test[&quot;HomePlanet&quot;] = test[&quot;HomePlanet&quot;].fillna(&#39;Z&#39;) . Encoding Categorical Features . text_features . [&#39;Cabin&#39;, &#39;Name&#39;] . cat_features . [&#39;HomePlanet&#39;, &#39;CryoSleep&#39;, &#39;Destination&#39;, &#39;VIP&#39;] . # def labelEncoder(data, columns): # for col in columns: # labels = [] # l_encoder = LabelEncoder() # items = data[col] # l_encoder.fit(items) # labels = l_encoder.transform(items) # data[col] = labels # le_name_mapping = dict(zip(l_encoder.classes_, l_encoder.transform(l_encoder.classes_))) # print(le_name_mapping) . . label_cols = [&quot;HomePlanet&quot;, &quot;CryoSleep&quot;,&quot;Cabin&quot;, &quot;Destination&quot; ,&quot;VIP&quot;] def label_encoder(train, test, columns): for col in columns: train[col] = train[col].astype(str) test[col] = test[col].astype(str) train[col] = LabelEncoder().fit_transform(train[col]) test[col] = LabelEncoder().fit_transform(test[col]) return train, test train, test = label_encoder(train, test ,label_cols) . train.drop([&quot;Name&quot; ,&quot;Cabin&quot;] , axis = 1 ,inplace = True) test.drop([&quot;Name&quot; ,&quot;Cabin&quot;] , axis = 1 ,inplace = True) X = train.drop(TARGET , axis =1 ) y = train[TARGET] X_train , X_test , y_train , y_test = train_test_split(X , y, random_state = 12 , test_size =0.33) . Step 5. Modeling . lgb_params = { &#39;objective&#39; : &#39;binary&#39;, &#39;n_estimators&#39; :50, &#39;learning_rate&#39; : 0.08 } lgb_predictions = 0 lgb_scores = [] lgb_fimp = [] LGBM_FEATURES = list(train.columns)[:-1] skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE) for fold, (train_idx, valid_idx) in enumerate(skf.split(train[LGBM_FEATURES], train[TARGET])): print(f&#39; 033[94m&#39;) print(10*&quot;=&quot;, f&quot;Fold={fold+1}&quot;, 10*&quot;=&quot;) start_time = time.time() X_train, X_valid = train.iloc[train_idx][LGBM_FEATURES], train.iloc[valid_idx][LGBM_FEATURES] y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx] model = LGBMClassifier(**lgb_params) model.fit(X_train, y_train,verbose=0) preds_valid = model.predict(X_valid) acc = accuracy_score(y_valid, preds_valid) lgb_scores.append(acc) run_time = time.time() - start_time fim = pd.DataFrame(index=LGBM_FEATURES, data=model.feature_importances_, columns=[f&#39;{fold}_importance&#39;]) lgb_fimp.append(fim) print(f&quot;Fold={fold+1}, Accuracy score: {acc:.2f}%, Run Time: {run_time:.2f}s&quot;) test_preds = model.predict(test[LGBM_FEATURES]) lgb_predictions += test_preds/FOLDS print(&quot;&quot;) print(&quot;Mean Accuracy :&quot;, np.mean(lgb_scores)) . ========== Fold=1 ========== Fold=1, Accuracy score: 0.81%, Run Time: 4.06s ========== Fold=2 ========== Fold=2, Accuracy score: 0.78%, Run Time: 1.70s ========== Fold=3 ========== Fold=3, Accuracy score: 0.79%, Run Time: 0.74s ========== Fold=4 ========== Fold=4, Accuracy score: 0.79%, Run Time: 0.11s ========== Fold=5 ========== Fold=5, Accuracy score: 0.81%, Run Time: 0.21s Mean Accuracy : 0.7958136330880743 . lgbm_fis_df = pd.concat(lgb_fimp, axis=1).head(15) lgbm_fis_df.sort_values(&#39;1_importance&#39;).plot(kind=&#39;barh&#39;, figsize=(15, 10), title=&#39;Feature Importance Across Folds&#39;) plt.show() . Step 6. Submission . submission[TARGET] = lgb_predictions.astype(&quot;bool&quot;) submission.to_csv(&quot;submission.csv&quot;,index=False) submission.head() . PassengerId Transported . 0 0013_01 | True | . 1 0018_01 | False | . 2 0019_01 | True | . 3 0021_01 | True | . 4 0023_01 | True | .",
            "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/kaggle/ml/2022/07/07/_07_08_Spaceship_Titanic_%ED%95%84%EC%82%AC.html",
            "relUrl": "/kaggle/ml/2022/07/07/_07_08_Spaceship_Titanic_%ED%95%84%EC%82%AC.html",
            "date": " • Jul 7, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://milhaud1201.github.io/Jihyeon-Tech-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}